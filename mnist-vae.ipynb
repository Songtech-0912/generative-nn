{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39971f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9e96eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, _), (test_images, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "331a2692",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 60000\n",
    "batch_size = 128\n",
    "test_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bf7f55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "918c5d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f13afac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = np.concatenate((train_images, test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cba6317f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a996216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "all_images = all_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50a1ad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = np.expand_dims(all_images, -1).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "19357bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 28, 28, 1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de9275c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input shape and latent dimension\n",
    "latent_dim = 2\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ade5be29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.random.normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13342d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 14, 14, 32)   320         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 7, 7, 64)     18496       ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 3136)         0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 16)           50192       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 2)            34          ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 2)            34          ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " sampling (Sampling)            (None, 2)            0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 69,076\n",
      "Trainable params: 69,076\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = keras.Input(shape=input_shape)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03e2cd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3136)              9408      \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       36928     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        289       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,089\n",
      "Trainable params: 65,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((7, 7, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98c80995",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab79edde",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a8b3f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a387b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "547/547 [==============================] - 35s 61ms/step - loss: 252.3632 - reconstruction_loss: 207.2607 - kl_loss: 3.4982\n",
      "Epoch 2/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 189.9171 - reconstruction_loss: 184.8132 - kl_loss: 3.3478\n",
      "Epoch 3/500\n",
      "547/547 [==============================] - 34s 61ms/step - loss: 181.5460 - reconstruction_loss: 171.8436 - kl_loss: 4.7440\n",
      "Epoch 4/500\n",
      "547/547 [==============================] - 33s 61ms/step - loss: 167.0588 - reconstruction_loss: 159.7827 - kl_loss: 6.0424\n",
      "Epoch 5/500\n",
      "547/547 [==============================] - 33s 61ms/step - loss: 163.3559 - reconstruction_loss: 156.5741 - kl_loss: 6.2479\n",
      "Epoch 6/500\n",
      "547/547 [==============================] - 34s 61ms/step - loss: 161.2735 - reconstruction_loss: 154.5706 - kl_loss: 6.3320\n",
      "Epoch 7/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 159.7084 - reconstruction_loss: 153.2637 - kl_loss: 6.3492\n",
      "Epoch 8/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 158.4713 - reconstruction_loss: 152.2343 - kl_loss: 6.3876\n",
      "Epoch 9/500\n",
      "547/547 [==============================] - 34s 61ms/step - loss: 157.9619 - reconstruction_loss: 151.3011 - kl_loss: 6.3921\n",
      "Epoch 10/500\n",
      "547/547 [==============================] - 33s 61ms/step - loss: 157.1897 - reconstruction_loss: 150.7013 - kl_loss: 6.4148\n",
      "Epoch 11/500\n",
      "547/547 [==============================] - 34s 61ms/step - loss: 156.5332 - reconstruction_loss: 149.9826 - kl_loss: 6.4078\n",
      "Epoch 12/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 156.1299 - reconstruction_loss: 149.5878 - kl_loss: 6.3988\n",
      "Epoch 13/500\n",
      "547/547 [==============================] - 34s 61ms/step - loss: 155.8328 - reconstruction_loss: 149.1220 - kl_loss: 6.4318\n",
      "Epoch 14/500\n",
      "547/547 [==============================] - 33s 61ms/step - loss: 155.3520 - reconstruction_loss: 148.7549 - kl_loss: 6.3775\n",
      "Epoch 15/500\n",
      "547/547 [==============================] - 33s 61ms/step - loss: 154.5170 - reconstruction_loss: 148.4228 - kl_loss: 6.3778\n",
      "Epoch 16/500\n",
      "547/547 [==============================] - 34s 61ms/step - loss: 154.7525 - reconstruction_loss: 148.1269 - kl_loss: 6.3898\n",
      "Epoch 17/500\n",
      "547/547 [==============================] - 34s 61ms/step - loss: 154.2835 - reconstruction_loss: 147.8063 - kl_loss: 6.3767\n",
      "Epoch 18/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 153.8598 - reconstruction_loss: 147.6019 - kl_loss: 6.3865\n",
      "Epoch 19/500\n",
      "547/547 [==============================] - 33s 61ms/step - loss: 153.1923 - reconstruction_loss: 147.3143 - kl_loss: 6.3594\n",
      "Epoch 20/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 153.5406 - reconstruction_loss: 147.1866 - kl_loss: 6.3379\n",
      "Epoch 21/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 153.3644 - reconstruction_loss: 147.0099 - kl_loss: 6.3448\n",
      "Epoch 22/500\n",
      "547/547 [==============================] - 33s 61ms/step - loss: 153.2861 - reconstruction_loss: 146.7808 - kl_loss: 6.3382\n",
      "Epoch 23/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 152.6324 - reconstruction_loss: 146.5160 - kl_loss: 6.3336\n",
      "Epoch 24/500\n",
      "547/547 [==============================] - 33s 61ms/step - loss: 153.1275 - reconstruction_loss: 146.4323 - kl_loss: 6.3313\n",
      "Epoch 25/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 152.8498 - reconstruction_loss: 146.3177 - kl_loss: 6.3210\n",
      "Epoch 26/500\n",
      "547/547 [==============================] - 34s 63ms/step - loss: 152.5146 - reconstruction_loss: 146.1638 - kl_loss: 6.3260\n",
      "Epoch 27/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 152.2162 - reconstruction_loss: 145.9333 - kl_loss: 6.3333\n",
      "Epoch 28/500\n",
      "547/547 [==============================] - 34s 61ms/step - loss: 151.6159 - reconstruction_loss: 145.7442 - kl_loss: 6.3448\n",
      "Epoch 29/500\n",
      "547/547 [==============================] - 33s 61ms/step - loss: 152.3300 - reconstruction_loss: 145.6845 - kl_loss: 6.3511\n",
      "Epoch 30/500\n",
      "547/547 [==============================] - 33s 61ms/step - loss: 151.7381 - reconstruction_loss: 145.5014 - kl_loss: 6.3412\n",
      "Epoch 31/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 151.4677 - reconstruction_loss: 145.4023 - kl_loss: 6.3456\n",
      "Epoch 32/500\n",
      "547/547 [==============================] - 33s 61ms/step - loss: 151.6270 - reconstruction_loss: 145.2453 - kl_loss: 6.3616\n",
      "Epoch 33/500\n",
      "547/547 [==============================] - 33s 61ms/step - loss: 151.4501 - reconstruction_loss: 145.1487 - kl_loss: 6.3687\n",
      "Epoch 34/500\n",
      "547/547 [==============================] - 33s 61ms/step - loss: 151.4317 - reconstruction_loss: 145.0508 - kl_loss: 6.3647\n",
      "Epoch 35/500\n",
      "547/547 [==============================] - 33s 61ms/step - loss: 151.1334 - reconstruction_loss: 144.9207 - kl_loss: 6.3753\n",
      "Epoch 36/500\n",
      "547/547 [==============================] - 34s 61ms/step - loss: 151.1976 - reconstruction_loss: 144.9036 - kl_loss: 6.3849\n",
      "Epoch 37/500\n",
      "547/547 [==============================] - 35s 63ms/step - loss: 150.9055 - reconstruction_loss: 144.8072 - kl_loss: 6.3836\n",
      "Epoch 38/500\n",
      "547/547 [==============================] - 33s 61ms/step - loss: 151.0963 - reconstruction_loss: 144.6785 - kl_loss: 6.3884\n",
      "Epoch 39/500\n",
      "547/547 [==============================] - 35s 63ms/step - loss: 150.9988 - reconstruction_loss: 144.4893 - kl_loss: 6.3968\n",
      "Epoch 40/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 150.7915 - reconstruction_loss: 144.4574 - kl_loss: 6.3899\n",
      "Epoch 41/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 151.0649 - reconstruction_loss: 144.3572 - kl_loss: 6.3970\n",
      "Epoch 42/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 150.3921 - reconstruction_loss: 144.2948 - kl_loss: 6.3830\n",
      "Epoch 43/500\n",
      "547/547 [==============================] - 34s 63ms/step - loss: 150.7913 - reconstruction_loss: 144.0625 - kl_loss: 6.4039\n",
      "Epoch 44/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 150.3037 - reconstruction_loss: 144.1562 - kl_loss: 6.4131\n",
      "Epoch 45/500\n",
      "547/547 [==============================] - 34s 63ms/step - loss: 150.1046 - reconstruction_loss: 144.0856 - kl_loss: 6.4173\n",
      "Epoch 46/500\n",
      "547/547 [==============================] - 35s 63ms/step - loss: 150.6278 - reconstruction_loss: 143.9483 - kl_loss: 6.4411\n",
      "Epoch 47/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 149.8706 - reconstruction_loss: 143.8886 - kl_loss: 6.4191\n",
      "Epoch 48/500\n",
      "547/547 [==============================] - 36s 65ms/step - loss: 149.8795 - reconstruction_loss: 143.7831 - kl_loss: 6.4291\n",
      "Epoch 49/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 149.8597 - reconstruction_loss: 143.6965 - kl_loss: 6.4327\n",
      "Epoch 50/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 150.0494 - reconstruction_loss: 143.6236 - kl_loss: 6.4342\n",
      "Epoch 51/500\n",
      "547/547 [==============================] - 35s 63ms/step - loss: 149.9656 - reconstruction_loss: 143.5782 - kl_loss: 6.4418\n",
      "Epoch 52/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 149.8996 - reconstruction_loss: 143.4943 - kl_loss: 6.4490\n",
      "Epoch 53/500\n",
      "547/547 [==============================] - 34s 63ms/step - loss: 150.1261 - reconstruction_loss: 143.4909 - kl_loss: 6.4486\n",
      "Epoch 54/500\n",
      "547/547 [==============================] - 35s 63ms/step - loss: 149.8372 - reconstruction_loss: 143.3863 - kl_loss: 6.4415\n",
      "Epoch 55/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 149.6004 - reconstruction_loss: 143.2278 - kl_loss: 6.4554\n",
      "Epoch 56/500\n",
      "547/547 [==============================] - 35s 63ms/step - loss: 149.5875 - reconstruction_loss: 143.3262 - kl_loss: 6.4606\n",
      "Epoch 57/500\n",
      "547/547 [==============================] - 35s 63ms/step - loss: 149.8589 - reconstruction_loss: 143.2461 - kl_loss: 6.4523\n",
      "Epoch 58/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 149.6156 - reconstruction_loss: 143.1572 - kl_loss: 6.4624\n",
      "Epoch 59/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 149.5363 - reconstruction_loss: 143.0995 - kl_loss: 6.4739\n",
      "Epoch 60/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 149.0023 - reconstruction_loss: 143.1115 - kl_loss: 6.4697\n",
      "Epoch 61/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 149.6360 - reconstruction_loss: 142.9667 - kl_loss: 6.4589\n",
      "Epoch 62/500\n",
      "547/547 [==============================] - 35s 65ms/step - loss: 149.3998 - reconstruction_loss: 142.8767 - kl_loss: 6.4677\n",
      "Epoch 63/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 149.0446 - reconstruction_loss: 142.9188 - kl_loss: 6.4719\n",
      "Epoch 64/500\n",
      "547/547 [==============================] - 35s 63ms/step - loss: 149.3882 - reconstruction_loss: 142.8155 - kl_loss: 6.4831\n",
      "Epoch 65/500\n",
      "547/547 [==============================] - 34s 61ms/step - loss: 149.4311 - reconstruction_loss: 142.9383 - kl_loss: 6.4598\n",
      "Epoch 66/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 149.0660 - reconstruction_loss: 142.8276 - kl_loss: 6.4685\n",
      "Epoch 67/500\n",
      "547/547 [==============================] - 34s 63ms/step - loss: 149.0474 - reconstruction_loss: 142.7083 - kl_loss: 6.4774\n",
      "Epoch 68/500\n",
      "547/547 [==============================] - 34s 63ms/step - loss: 149.1181 - reconstruction_loss: 142.6493 - kl_loss: 6.4915\n",
      "Epoch 69/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 149.0897 - reconstruction_loss: 142.6183 - kl_loss: 6.4778\n",
      "Epoch 70/500\n",
      "547/547 [==============================] - 34s 63ms/step - loss: 148.6678 - reconstruction_loss: 142.6073 - kl_loss: 6.4919\n",
      "Epoch 71/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 149.0750 - reconstruction_loss: 142.5784 - kl_loss: 6.4822\n",
      "Epoch 72/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 148.8901 - reconstruction_loss: 142.5016 - kl_loss: 6.5000\n",
      "Epoch 73/500\n",
      "547/547 [==============================] - 34s 63ms/step - loss: 148.8110 - reconstruction_loss: 142.5253 - kl_loss: 6.4862\n",
      "Epoch 74/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 148.8246 - reconstruction_loss: 142.4956 - kl_loss: 6.4849\n",
      "Epoch 75/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 148.8395 - reconstruction_loss: 142.4312 - kl_loss: 6.5044\n",
      "Epoch 76/500\n",
      "547/547 [==============================] - 34s 63ms/step - loss: 148.9348 - reconstruction_loss: 142.3436 - kl_loss: 6.4887\n",
      "Epoch 77/500\n",
      "547/547 [==============================] - 34s 63ms/step - loss: 148.3885 - reconstruction_loss: 142.3895 - kl_loss: 6.4995\n",
      "Epoch 78/500\n",
      "547/547 [==============================] - 34s 63ms/step - loss: 148.6830 - reconstruction_loss: 142.3121 - kl_loss: 6.4876\n",
      "Epoch 79/500\n",
      "547/547 [==============================] - 34s 63ms/step - loss: 148.8853 - reconstruction_loss: 142.2528 - kl_loss: 6.5171\n",
      "Epoch 80/500\n",
      "547/547 [==============================] - 35s 63ms/step - loss: 148.9294 - reconstruction_loss: 142.2805 - kl_loss: 6.5006\n",
      "Epoch 81/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 148.6367 - reconstruction_loss: 142.1731 - kl_loss: 6.5219\n",
      "Epoch 82/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 148.6727 - reconstruction_loss: 142.1442 - kl_loss: 6.5068\n",
      "Epoch 83/500\n",
      "547/547 [==============================] - 34s 61ms/step - loss: 147.9990 - reconstruction_loss: 142.0252 - kl_loss: 6.5190\n",
      "Epoch 84/500\n",
      "547/547 [==============================] - 34s 61ms/step - loss: 148.1667 - reconstruction_loss: 142.1131 - kl_loss: 6.5177\n",
      "Epoch 85/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 148.4626 - reconstruction_loss: 142.1027 - kl_loss: 6.5127\n",
      "Epoch 86/500\n",
      "547/547 [==============================] - 34s 61ms/step - loss: 148.7469 - reconstruction_loss: 142.0117 - kl_loss: 6.5006\n",
      "Epoch 87/500\n",
      "547/547 [==============================] - 35s 63ms/step - loss: 148.5992 - reconstruction_loss: 142.0003 - kl_loss: 6.5043\n",
      "Epoch 88/500\n",
      "547/547 [==============================] - 36s 66ms/step - loss: 148.1630 - reconstruction_loss: 141.9565 - kl_loss: 6.5001\n",
      "Epoch 89/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 148.7055 - reconstruction_loss: 141.9579 - kl_loss: 6.5094\n",
      "Epoch 90/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 148.2995 - reconstruction_loss: 141.8837 - kl_loss: 6.5192\n",
      "Epoch 91/500\n",
      "547/547 [==============================] - 34s 61ms/step - loss: 148.1961 - reconstruction_loss: 141.8279 - kl_loss: 6.5154\n",
      "Epoch 92/500\n",
      "547/547 [==============================] - 34s 63ms/step - loss: 148.4861 - reconstruction_loss: 141.8273 - kl_loss: 6.5200\n",
      "Epoch 93/500\n",
      "547/547 [==============================] - 35s 63ms/step - loss: 147.9868 - reconstruction_loss: 141.7855 - kl_loss: 6.5158\n",
      "Epoch 94/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 148.0643 - reconstruction_loss: 141.7795 - kl_loss: 6.5159\n",
      "Epoch 95/500\n",
      "547/547 [==============================] - 34s 63ms/step - loss: 148.5799 - reconstruction_loss: 141.7984 - kl_loss: 6.5347\n",
      "Epoch 96/500\n",
      "547/547 [==============================] - 34s 63ms/step - loss: 148.1939 - reconstruction_loss: 141.7053 - kl_loss: 6.5391\n",
      "Epoch 97/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 148.2807 - reconstruction_loss: 141.7056 - kl_loss: 6.5199\n",
      "Epoch 98/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 147.8481 - reconstruction_loss: 141.7540 - kl_loss: 6.5199\n",
      "Epoch 99/500\n",
      "547/547 [==============================] - 34s 63ms/step - loss: 148.2527 - reconstruction_loss: 141.6706 - kl_loss: 6.5247\n",
      "Epoch 100/500\n",
      "547/547 [==============================] - 35s 63ms/step - loss: 148.0010 - reconstruction_loss: 141.6699 - kl_loss: 6.5360\n",
      "Epoch 101/500\n",
      "547/547 [==============================] - 34s 63ms/step - loss: 148.1381 - reconstruction_loss: 141.6687 - kl_loss: 6.5323\n",
      "Epoch 102/500\n",
      "547/547 [==============================] - 34s 63ms/step - loss: 147.8787 - reconstruction_loss: 141.5404 - kl_loss: 6.5417\n",
      "Epoch 103/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 147.8550 - reconstruction_loss: 141.5871 - kl_loss: 6.5233\n",
      "Epoch 104/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 147.9371 - reconstruction_loss: 141.4995 - kl_loss: 6.5446\n",
      "Epoch 105/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 148.0896 - reconstruction_loss: 141.5582 - kl_loss: 6.5441\n",
      "Epoch 106/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 147.9100 - reconstruction_loss: 141.4427 - kl_loss: 6.5357\n",
      "Epoch 107/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 147.8598 - reconstruction_loss: 141.4565 - kl_loss: 6.5294\n",
      "Epoch 108/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 147.9612 - reconstruction_loss: 141.4479 - kl_loss: 6.5438\n",
      "Epoch 109/500\n",
      "547/547 [==============================] - 34s 63ms/step - loss: 148.0783 - reconstruction_loss: 141.3974 - kl_loss: 6.5291\n",
      "Epoch 110/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 148.3209 - reconstruction_loss: 141.4202 - kl_loss: 6.5280\n",
      "Epoch 111/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 147.7057 - reconstruction_loss: 141.3917 - kl_loss: 6.5358\n",
      "Epoch 112/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 147.6890 - reconstruction_loss: 141.3539 - kl_loss: 6.5447\n",
      "Epoch 113/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 147.7582 - reconstruction_loss: 141.3842 - kl_loss: 6.5393\n",
      "Epoch 114/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 147.7147 - reconstruction_loss: 141.2755 - kl_loss: 6.5521\n",
      "Epoch 115/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 147.1983 - reconstruction_loss: 141.1757 - kl_loss: 6.5417\n",
      "Epoch 116/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 147.9056 - reconstruction_loss: 141.2789 - kl_loss: 6.5574\n",
      "Epoch 117/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 147.3110 - reconstruction_loss: 141.1704 - kl_loss: 6.5458\n",
      "Epoch 118/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 147.8098 - reconstruction_loss: 141.2222 - kl_loss: 6.5539\n",
      "Epoch 119/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 [==============================] - 35s 64ms/step - loss: 147.6166 - reconstruction_loss: 141.2287 - kl_loss: 6.5625\n",
      "Epoch 120/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 147.5276 - reconstruction_loss: 141.1695 - kl_loss: 6.5544\n",
      "Epoch 121/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 147.2451 - reconstruction_loss: 141.1345 - kl_loss: 6.5467\n",
      "Epoch 122/500\n",
      "547/547 [==============================] - 34s 63ms/step - loss: 147.6354 - reconstruction_loss: 141.1175 - kl_loss: 6.5597\n",
      "Epoch 123/500\n",
      "547/547 [==============================] - 37s 67ms/step - loss: 147.1632 - reconstruction_loss: 141.1368 - kl_loss: 6.5603\n",
      "Epoch 124/500\n",
      "547/547 [==============================] - 36s 65ms/step - loss: 147.7343 - reconstruction_loss: 141.1447 - kl_loss: 6.5676\n",
      "Epoch 125/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 147.7294 - reconstruction_loss: 141.0587 - kl_loss: 6.5603\n",
      "Epoch 126/500\n",
      "547/547 [==============================] - 36s 65ms/step - loss: 147.3101 - reconstruction_loss: 141.0499 - kl_loss: 6.5718\n",
      "Epoch 127/500\n",
      "547/547 [==============================] - 36s 65ms/step - loss: 147.5746 - reconstruction_loss: 141.1182 - kl_loss: 6.5455\n",
      "Epoch 128/500\n",
      "547/547 [==============================] - 35s 63ms/step - loss: 147.3912 - reconstruction_loss: 140.9825 - kl_loss: 6.5516\n",
      "Epoch 129/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 147.3353 - reconstruction_loss: 141.0205 - kl_loss: 6.5695\n",
      "Epoch 130/500\n",
      "547/547 [==============================] - 36s 65ms/step - loss: 147.5973 - reconstruction_loss: 140.9129 - kl_loss: 6.5697\n",
      "Epoch 131/500\n",
      "547/547 [==============================] - 35s 65ms/step - loss: 147.7061 - reconstruction_loss: 140.9568 - kl_loss: 6.5653\n",
      "Epoch 132/500\n",
      "547/547 [==============================] - 36s 65ms/step - loss: 147.2310 - reconstruction_loss: 140.9486 - kl_loss: 6.5444\n",
      "Epoch 133/500\n",
      "547/547 [==============================] - 34s 63ms/step - loss: 147.2503 - reconstruction_loss: 140.9313 - kl_loss: 6.5676\n",
      "Epoch 134/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 147.3331 - reconstruction_loss: 140.9545 - kl_loss: 6.5715\n",
      "Epoch 135/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 147.3523 - reconstruction_loss: 140.8599 - kl_loss: 6.5501\n",
      "Epoch 136/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 147.4744 - reconstruction_loss: 140.9257 - kl_loss: 6.5730\n",
      "Epoch 137/500\n",
      "547/547 [==============================] - 35s 63ms/step - loss: 147.0780 - reconstruction_loss: 140.8532 - kl_loss: 6.5731\n",
      "Epoch 138/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 147.3456 - reconstruction_loss: 140.8398 - kl_loss: 6.5670\n",
      "Epoch 139/500\n",
      "547/547 [==============================] - 35s 63ms/step - loss: 147.3267 - reconstruction_loss: 140.8227 - kl_loss: 6.5581\n",
      "Epoch 140/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 147.2901 - reconstruction_loss: 140.7835 - kl_loss: 6.5777\n",
      "Epoch 141/500\n",
      "547/547 [==============================] - 35s 63ms/step - loss: 147.2238 - reconstruction_loss: 140.7765 - kl_loss: 6.5714\n",
      "Epoch 142/500\n",
      "547/547 [==============================] - 35s 63ms/step - loss: 147.4987 - reconstruction_loss: 140.8313 - kl_loss: 6.5764\n",
      "Epoch 143/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 147.0767 - reconstruction_loss: 140.7877 - kl_loss: 6.5852\n",
      "Epoch 144/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 146.9766 - reconstruction_loss: 140.6901 - kl_loss: 6.5897\n",
      "Epoch 145/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 147.3432 - reconstruction_loss: 140.7376 - kl_loss: 6.5792\n",
      "Epoch 146/500\n",
      "547/547 [==============================] - 35s 65ms/step - loss: 147.5373 - reconstruction_loss: 140.6742 - kl_loss: 6.5759\n",
      "Epoch 147/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 146.8716 - reconstruction_loss: 140.7410 - kl_loss: 6.5791\n",
      "Epoch 148/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 146.6685 - reconstruction_loss: 140.6705 - kl_loss: 6.5735\n",
      "Epoch 149/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 147.2557 - reconstruction_loss: 140.6153 - kl_loss: 6.5697\n",
      "Epoch 150/500\n",
      "547/547 [==============================] - 35s 63ms/step - loss: 146.8531 - reconstruction_loss: 140.6410 - kl_loss: 6.5828\n",
      "Epoch 151/500\n",
      "547/547 [==============================] - 36s 65ms/step - loss: 147.2219 - reconstruction_loss: 140.6776 - kl_loss: 6.5895\n",
      "Epoch 152/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 147.7170 - reconstruction_loss: 140.6352 - kl_loss: 6.5744\n",
      "Epoch 153/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 147.0666 - reconstruction_loss: 140.6131 - kl_loss: 6.5859\n",
      "Epoch 154/500\n",
      "547/547 [==============================] - 36s 65ms/step - loss: 146.8546 - reconstruction_loss: 140.5772 - kl_loss: 6.5646\n",
      "Epoch 155/500\n",
      "547/547 [==============================] - 35s 65ms/step - loss: 147.6944 - reconstruction_loss: 140.5567 - kl_loss: 6.5833\n",
      "Epoch 156/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 146.8698 - reconstruction_loss: 140.4686 - kl_loss: 6.5775\n",
      "Epoch 157/500\n",
      "547/547 [==============================] - 34s 63ms/step - loss: 147.0838 - reconstruction_loss: 140.6311 - kl_loss: 6.5838\n",
      "Epoch 158/500\n",
      "547/547 [==============================] - 34s 63ms/step - loss: 146.8419 - reconstruction_loss: 140.6503 - kl_loss: 6.5665\n",
      "Epoch 159/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 146.7323 - reconstruction_loss: 140.5135 - kl_loss: 6.5982\n",
      "Epoch 160/500\n",
      "547/547 [==============================] - 36s 65ms/step - loss: 146.8204 - reconstruction_loss: 140.4790 - kl_loss: 6.5805\n",
      "Epoch 161/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 146.7657 - reconstruction_loss: 140.5392 - kl_loss: 6.5919\n",
      "Epoch 162/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 146.7253 - reconstruction_loss: 140.4672 - kl_loss: 6.5946\n",
      "Epoch 163/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 146.9301 - reconstruction_loss: 140.4550 - kl_loss: 6.5911\n",
      "Epoch 164/500\n",
      "547/547 [==============================] - 38s 70ms/step - loss: 146.7634 - reconstruction_loss: 140.4032 - kl_loss: 6.5864\n",
      "Epoch 165/500\n",
      "547/547 [==============================] - 36s 66ms/step - loss: 147.0401 - reconstruction_loss: 140.4685 - kl_loss: 6.5926\n",
      "Epoch 166/500\n",
      "547/547 [==============================] - 36s 65ms/step - loss: 146.7349 - reconstruction_loss: 140.3552 - kl_loss: 6.5847\n",
      "Epoch 167/500\n",
      "547/547 [==============================] - 34s 63ms/step - loss: 146.5255 - reconstruction_loss: 140.3741 - kl_loss: 6.5879\n",
      "Epoch 168/500\n",
      "547/547 [==============================] - 34s 63ms/step - loss: 146.8366 - reconstruction_loss: 140.3566 - kl_loss: 6.5930\n",
      "Epoch 169/500\n",
      "547/547 [==============================] - 35s 63ms/step - loss: 146.8861 - reconstruction_loss: 140.4222 - kl_loss: 6.5875\n",
      "Epoch 170/500\n",
      "547/547 [==============================] - 34s 62ms/step - loss: 147.0259 - reconstruction_loss: 140.3735 - kl_loss: 6.5975\n",
      "Epoch 171/500\n",
      "547/547 [==============================] - 34s 63ms/step - loss: 147.0695 - reconstruction_loss: 140.3673 - kl_loss: 6.5854\n",
      "Epoch 172/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 146.8393 - reconstruction_loss: 140.3240 - kl_loss: 6.5803\n",
      "Epoch 173/500\n",
      "547/547 [==============================] - 35s 64ms/step - loss: 146.9281 - reconstruction_loss: 140.3974 - kl_loss: 6.5944\n",
      "Epoch 174/500\n",
      "129/547 [======>.......................] - ETA: 26s - loss: 146.4418 - reconstruction_loss: 140.2258 - kl_loss: 6.6363"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vae.fit(all_images, epochs=500, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc12b7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.save_weights(\"vae-mnist-5-weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34e9c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_img():\n",
    "    random_latent_vectors = np.random.random((1, 28, 28, 1))\n",
    "    _, _, z = vae.encoder.predict(random_latent_vectors)\n",
    "    decoded_img = vae.decoder.predict(z)\n",
    "    fig = plt.figure(figsize=(1, 1))\n",
    "    plt.imshow(decoded_img[0], cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "733d78fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c025688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a2b91f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_img()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
